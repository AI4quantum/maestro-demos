apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: arxiv-normalize-url
  labels:
    app: summary-pipeline
spec:
  framework: code
  mode: local
  description: Normalize an arXiv URL/ID to a canonical arXiv ID string.
  instructions: Use input[0] and set output to the canonical arXiv ID.
  code: |
    import re

    def extract_arxiv_id(url: str) -> str:
        patterns = [
            r"arxiv\.org/abs/([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)",
            r"arxiv\.org/pdf/([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)",
            r"^([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)$"
        ]
        for pattern in patterns:
            m = re.search(pattern, url)
            if m:
                arxiv_id = m.group(1)
                return re.sub(r"v[0-9]+$", "", arxiv_id)
        return ""

    url_or_id = input[0]
    output = extract_arxiv_id(url_or_id)

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: arxiv-extract-fulltext
  labels:
    app: summary-pipeline
spec:
  framework: code
  mode: local
  description: Download by arXiv URL or ID, extract with Docling, clean boilerplate, output cleaned text.
  instructions: Use input[0] (URL or ID). Normalize to an arXiv ID and set output to the cleaned text.
  code: |
    import os
    import re
    import requests
    from docling.document_converter import DocumentConverter, PdfFormatOption
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions

    def _extract_arxiv_id(url_or_id: str) -> str:
        patterns = [
            r"arxiv\.org/abs/([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)",
            r"arxiv\.org/pdf/([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)",
            r"^([0-9]{4}\.[0-9]{4,5}(?:v[0-9]+)?)$",
        ]
        for p in patterns:
            m = re.search(p, url_or_id)
            if m:
                return re.sub(r"v[0-9]+$", "", m.group(1))
        return url_or_id.strip()

    def _download_arxiv_pdf(arxiv_id: str, download_dir: str = "/tmp"):
        url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=30)
        r.raise_for_status()
        pdf_path = os.path.join(download_dir, f"{arxiv_id}.pdf")
        with open(pdf_path, "wb") as f:
            f.write(r.content)
        return pdf_path

    def _extract_text_with_docling(pdf_path: str) -> str:
        opts = PdfPipelineOptions()
        opts.do_ocr = True
        opts.do_table_structure = True
        opts.table_structure_options.do_cell_matching = True
        fmt = PdfFormatOption(pipeline_options=opts)
        conv = DocumentConverter(format_options={InputFormat.PDF: fmt})
        result = conv.convert(pdf_path)
        return result.document.export_to_text()

    def _clean_research_text(text: str) -> str:
        s = text.replace("\r\n", "\n").replace("\r", "\n")
        s = re.sub(r"(\w+)-\n(\w+)", r"\1\2\n", s)
        lines = s.splitlines()

        n = len(lines)
        cutoff = int(n * 0.6)
        cut_idx = None
        for i in range(cutoff, n):
            raw = lines[i].strip()
            t = re.sub(r"^[#\s\-\d\.:\)]+", "", raw).lower()
            if re.match(r"^(references|bibliography)\b", t) or re.match(r"^(acknowledgments|acknowledgements|appendix)\b", t):
                cut_idx = i
                break
        if cut_idx is not None:
            lines = lines[:cut_idx]
        else:
            ref_bullet = re.compile(r"^\s*([\-â€¢]\s*\[\d+\]|\[\d+\]|\d+\.|\d+\))\s+")
            for i in range(cutoff, n):
                window = lines[i:i+7]
                hits = sum(1 for ln in window if ref_bullet.match(ln or ""))
                if hits >= 3:
                    lines = lines[:i]
                    break

        cleaned = []
        for ln in lines:
            t = ln.strip()
            if not t:
                cleaned.append("")
                continue
            if re.fullmatch(r"https?://\S+", t):
                continue
            if re.fullmatch(r"\d+|\d+\s*/\s*\d+|(?i:page)\s*\d+(\s*(?i:of)\s*\d+)?", t):
                continue
            if re.match(r"^(Figure|Fig\.|Table)\s+\d+([:.\s]|$)", t, re.IGNORECASE):
                continue
            t = re.sub(r"\S+@\S+", "", t)
            t = re.sub(r"\s{2,}", " ", t).strip()
            cleaned.append(t)

        s = "\n".join(cleaned)
        s = re.sub(r"\n{3,}", "\n\n", s).strip()
        return s

    arxiv_id = _extract_arxiv_id(input[0])
    pdf = _download_arxiv_pdf(arxiv_id)
    raw = _extract_text_with_docling(pdf)
    output = _clean_research_text(raw)
