apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: slack
  labels:
    app: slack-example
    custom_agent: slack_agent
spec:
  model: dummy
  framework: custom
  mode: remote
  description: slack agent
  instructions: post a message to slack

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: Paper Finder
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Retrieve IBM related papers from a certain topic in a certain time frame"
  instructions: |
    Input:
          • category (string) # e.g. "quantum-ph"
          • since_days (int)  # e.g. "1" for the last 1 days since today's date.

        Task:
          1. Call the ibm-arXiv tool to search for all papers on `category` published in the last `since_days`. All the functionality is already implemented in the funciton, simply execute the function with the given parameters as the input, and then return the output (which should be titles of research papers) into a list.
          Directly print out the list in the output.
  code: |
    import arxiv
    import feedparser
    from datetime import datetime, timedelta, timezone
    from typing import List, Dict
    from urllib.parse import urlencode

    def find_ibm_papers(
        category: str,
        since_days: int,
    ) -> List[Dict]:
        """
        Search ArXiv in `category`, pre-filter by abstract keywords, then
        post-filter by author affiliation tags—handling URL encoding properly.
        """
      
        ibm_keywords = ["ibm", "watson", "powerai", "ibm research"]

        cutoff = datetime.now(timezone.utc) - timedelta(days=since_days)
        abs_filter = " OR ".join(f'abs:"{kw}"' for kw in ibm_keywords)
        query = f"cat:{category} AND ({abs_filter})"
        params = {
            "search_query": query,
            "start": 0,
            "max_results": 100,
            "sortBy": "submittedDate",
            "sortOrder": "descending",
        }
        base_url = "http://export.arxiv.org/api/query?"
        url = base_url + urlencode(params)

        feed = feedparser.parse(url)
        papers = []

        for entry in feed.entries:
            published = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            if published < cutoff:
                continue

            abstract = entry.summary.lower()
            keyword_match = any(kw.lower() in abstract for kw in ibm_keywords)

            affs = entry.get("arxiv_affiliation", [])
            affiliation_match = any("ibm" in aff.lower() for aff in affs)

            if not (keyword_match or affiliation_match):
                continue

            papers.append(entry.title)

        return papers
  tools:
    - 'find_ibm_papers'

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: get metadata
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Retrieve metadata for a given arxiv paper"
  instructions: |
    The input will be a title (in list format) to a research paper. Extract this from the list and use it as the input for a parameter for the function in step 1.  Example given input might be like this: ["This is an example input title"]. We only want to extract and use the string inside, "This is an exmaple input title" and set this as our title.

    Step1:
    Use the *get_metadata tool*, passing in the given title to retreive the abstract for the paper.  The function call should just be `get_metadata_by_title(title)`. 

    Currently you are using the Thought, Result, and Reason step which is the final output that is generated. However, I want you to stop at the Result step (which should directly just be the output of the function). *STRICTLY output the result of the function and nothing else*
    Example output that the user should see:
        {
          "title": inputted title,
          "authors": [
            authors retrieved by the function
          ],
          "published": date retrieved by the function,
          "abstract": abstract retrieved by the function
        }
  code: |
    import arxiv
    from typing import Optional

    def get_metadata_by_title(title: str) -> Optional[str]:
        """
        Given the exact title of an arXiv paper, fetch its abstract.
        Returns None if no match is found.
        """
        client = arxiv.Client()
        search = arxiv.Search(
            query=f'ti:"{title}"',
            max_results=1
        )
        result = next(client.results(search), None)
        if not result:
            return None
        return {
            "title":     result.title,
            "authors":   [a.name for a in result.authors],
            "published": result.published.strftime("%Y-%m-%d"),
            "abstract":  result.summary.strip()
        }
  tools:
    - 'get_metadata_by_title'

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: generate summary
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Generate summary using metadata"
  instructions: |
    You are a paper‐summary agent. You will receive exactly one valid JSON object as your input. This JSON object contains metadata about a research paper, including the title, authors, publication date, and abstract.
    Your task is to output a two-paragraph plain-text summary in the following format using the LLM tool:

    **Header Line:**
    `{title}, by {Author1, Author2, …} (Published: {published})`

    **Expanded Summary:**

    **Paragraph 1:** Begin by restating the core topic and main objective of the paper based on the provided abstract. Then, expand on the key findings, results, or contributions mentioned in the abstract. Use clear and concise language, aiming to provide a more detailed explanation than the original abstract while maintaining accuracy.

    **Paragraph 2:** Identify and explain any crucial technical terms, methodologies, or concepts that are essential for understanding the paper's context and significance. Frame these explanations in a way that a general technical reader, who may not be an expert in the specific field, can grasp their meaning and relevance to the research.

    **Constraints:**
    - Do not output JSON or attempt to look up anything.
    - Do not include extra sections or bullet points within the paragraphs (except for the header line format).
    - Ensure the full summary is approximately 150–200 words.

  tools: 
    - 'LLM'